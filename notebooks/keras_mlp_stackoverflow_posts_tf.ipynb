{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification of StackOverflow using TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from os import pardir, getcwd\n",
    "from os.path import join, abspath\n",
    "PARENT_DIRECTORY = abspath(join(getcwd(), pardir))\n",
    "sys.path.insert(0, PARENT_DIRECTORY)\n",
    "\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "import talos as ta\n",
    "warnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "from definitions import TALOS_DIR\n",
    "from app.preprocessing import load_dataset,preprocess_data\n",
    "from app.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing for the loaded Dataset\n",
    "1. Remove *punctuation* characters\n",
    "2. Remove *stopwords*\n",
    "3. Remove *links*\n",
    "4. Remove *Numbers*\n",
    "5. Format into *lowercase*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql              2000\n",
      "ruby-on-rails    2000\n",
      "android          2000\n",
      "angularjs        2000\n",
      "asp.net          2000\n",
      "c                2000\n",
      "c#               2000\n",
      "c++              2000\n",
      "css              2000\n",
      "html             2000\n",
      "ios              2000\n",
      "iphone           2000\n",
      "java             2000\n",
      "javascript       2000\n",
      "jquery           2000\n",
      "mysql            2000\n",
      "objective-c      2000\n",
      "php              2000\n",
      "python           2000\n",
      ".net             2000\n",
      "Name: tags, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(load_from_pickle=True)\n",
    "Classes = list(data['tags'].value_counts().index)\n",
    "Nclasses = len(Classes)\n",
    "print(data['tags'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP classifier in Keras using not standardized tf*idf features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Hyper parameter tuning for the **tf-idf** model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% Train & 10% HeldOut & 20% Test\n",
    "model_data_tf = preprocess_data(data, 'tags', 'post',\n",
    "                                input_ins='as_tf_idf',\n",
    "                                cv_split_full=0.2,\n",
    "                                cv_split_dev=0.125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visualize_proccess': False, 'first_neuron': 128, 'activation': 'tanh', 'dropout': 0.6, 'number_of_hidden_layers': 1, 'shapes': 'funnel', 'epochs': 20, 'batch_size': 64, 'model_type': 'keras_tf_idf_model'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 17%|█▋        | 1/6 [01:19<06:36, 79.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visualize_proccess': False, 'first_neuron': 64, 'activation': 'relu', 'dropout': 0.2, 'number_of_hidden_layers': 1, 'shapes': 'funnel', 'epochs': 15, 'batch_size': 32, 'model_type': 'keras_tf_idf_model'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 2/6 [02:18<04:52, 73.15s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visualize_proccess': False, 'first_neuron': 128, 'activation': 'tanh', 'dropout': 0.2, 'number_of_hidden_layers': 2, 'shapes': 'funnel', 'epochs': 15, 'batch_size': 64, 'model_type': 'keras_tf_idf_model'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 3/6 [03:17<03:27, 69.05s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'visualize_proccess': False, 'first_neuron': 128, 'activation': 'relu', 'dropout': 0.2, 'number_of_hidden_layers': 1, 'shapes': 'funnel', 'epochs': 20, 'batch_size': 64, 'model_type': 'keras_tf_idf_model'}\n"
     ]
    }
   ],
   "source": [
    "'''Use the test filename if ypu don't want to delete\n",
    "    # your current logs from the previous run.'''\n",
    "TALOS_TF_LOG_FILENAME = 'talos_tf_log_test'\n",
    "\n",
    "#--- In case of production logs comment out the below filename\n",
    "#TALOS_TF_LOG_FILENAME = 'talos_tf_log'\n",
    "talos_tf_log_pathname = os.path.join(TALOS_DIR, TALOS_TF_LOG_FILENAME)\n",
    "\n",
    "###### Production configuration\n",
    "tf_idf_model_config = {\n",
    "    'visualize_proccess': [False],\n",
    "    'first_neuron': [64, 128],  # First Layer\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'dropout': [0.2, 0.6],\n",
    "    'number_of_hidden_layers': [1, 2],\n",
    "    'shapes':['funnel'],\n",
    "    'epochs': [15, 20],\n",
    "    'batch_size': [32, 64],\n",
    "    'model_type': ['keras_tf_idf_model'],\n",
    "}\n",
    "\n",
    "history_model_tf_idf = ta.Scan(model_data_tf['x_train'],\n",
    "                               model_data_tf['y_train'],\n",
    "                               x_val=model_data_tf['x_train_dev'],\n",
    "                               y_val=model_data_tf['y_train_dev'],\n",
    "                               model=load_model,\n",
    "                               params=tf_idf_model_config,\n",
    "                               grid_downsample=0.1,\n",
    "                               print_params=True,\n",
    "                               seed=(123),\n",
    "                               dataset_name=talos_tf_log_pathname\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Finds the best model configuration set for the TF-IDF, after the Talos Scanning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_tf = ta.Reporting(history_model_tf_idf)\n",
    "best_model_idx = report_tf.data['val_f1'].idxmax()\n",
    "best_model_params = report_tf.data.loc[best_model_idx].to_dict()\n",
    "best_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Trains and fit the MLP Network  using the best selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tf_history, model_tf = load_model(model_data_tf['x_train'],\n",
    "                                        model_data_tf['y_train'],\n",
    "                                        model_data_tf['x_train_dev'],\n",
    "                                        model_data_tf['y_train_dev'],\n",
    "                                        best_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model History Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.visualization import plot_history_metrics\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plot_history_metrics(history_obj=model_tf_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance model\n",
    "\n",
    "Evaluates the performance of the best trained model in the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tf = model_tf.evaluate(model_data_tf['x_test'],\n",
    "                             model_data_tf['y_test'],\n",
    "                             batch_size=best_model_params['batch_size'],\n",
    "                             verbose=1)\n",
    "\n",
    "print('\\nTest f1: %.4f' % (score_tf[1]))\n",
    "print('\\nTest categorical accuracy: %.4f'% (score_tf[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Perfomance of **non-standardized** TF-IDF  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from app.visualization import (plot_prediction_metrics,\n",
    "                               create_clf_report,\n",
    "                               plot_roc_curve,\n",
    "                               plot_precision_recall_curve,\n",
    "                               plot_confusion_matrix)\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "prediction_val_tf = model_tf.predict(model_data_tf['x_test'], batch_size=best_model_params['batch_size'])\n",
    "\n",
    "# returns each entry result to the classification with the relevant probabilities\n",
    "y_pred_processed_tf = np.array([np.argmax(val) for val in prediction_val_tf])\n",
    "y_true_processed_tf = np.array([np.argmax(val) for val in model_data_tf['y_test']])\n",
    "\n",
    "# If you want to see the OneVSAll ROC Curves of each class uncomment the below line\n",
    "# plot_roc_curve(model_data_tf['y_test'], prediction_val_tf, Classes, 1)\n",
    "\n",
    "# If you want to see the OneVSAll Precission Recall Curves of each class, comment out the below line\n",
    "# plot_precision_recall_curve(model_data_tf['y_test'], prediction_val_tf, Classes , 1)\n",
    "\n",
    "# If you want to get the Classification Report, comment out the below line\n",
    "create_clf_report(y_true_processed_tf, y_pred_processed_tf, Classes)\n",
    "\n",
    "# If you want to get the confusion matrix,comment out the below line\n",
    "plot_confusion_matrix(y_true_processed_tf, y_pred_processed_tf, Classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP classifier in Keras using standardized tf*idf features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% Train & 30% Test\n",
    "# 70% Train-Dev % 30* Train-Dev \n",
    "model_data_sdr_tf = preprocess_data(data, 'tags', 'post',\n",
    "                                 input_ins='as_tf_idf',\n",
    "                                 cv_split_full=0.2,\n",
    "                                 cv_split_dev=0.125,\n",
    "                                 standarize=True\n",
    "                                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TALOS_SDR_TF_LOG_FILENAME = 'talos_sdr_tf_log_test'\n",
    "#TALOS_SDR_TF_LOG_FILENAME = 'talos_sdr_tf_log'\n",
    "talos_sdr_tf_log_pathname = os.path.join(TALOS_DIR, TALOS_SDR_TF_LOG_FILENAME)\n",
    "\n",
    "##### Production configuration\n",
    "history_model_tf_idf = ta.Scan(model_data_tf['x_train'],\n",
    "                               model_data_tf['y_train'],\n",
    "                               x_val=model_data_tf['x_train_dev'],\n",
    "                               y_val=model_data_tf['y_train_dev'],\n",
    "                               model=load_model,\n",
    "                               params=tf_idf_model_config,\n",
    "                               grid_downsample=0.1,\n",
    "                               print_params=True,\n",
    "                               seed=(123),\n",
    "                               dataset_name=talos_sdr_tf_log_pathname\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report_sdr_stf = ta.Reporting(history_model_tf_idf)\n",
    "best_model_sdr_idx = report_sdr_stf.data['val_f1'].idxmax()\n",
    "best_model_sdr_params = report_sdr_stf.data.loc[best_model_sdr_idx].to_dict()\n",
    "best_model_sdr_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sdr_tf_history, model_sdr_tf = load_model(model_data_tf['x_train'],\n",
    "                                                model_data_tf['y_train'],\n",
    "                                                model_data_tf['x_train_dev'],\n",
    "                                                model_data_tf['y_train_dev'],\n",
    "                                                best_model_sdr_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model History Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.visualization import plot_history_metrics\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plot_history_metrics(history_obj=model_sdr_tf_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance model\n",
    "\n",
    "Evaluates the performance of the best trained model in the **test** dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_sdr_tf = model_sdr_tf.evaluate(model_data_tf['x_test'],\n",
    "                                 model_data_tf['y_test'],\n",
    "                                 batch_size=best_model_sdr_params['batch_size'],\n",
    "                                 verbose=1)\n",
    "\n",
    "print('\\nTest f1: %.4f' % (score_sdr_tf[1]))\n",
    "print('\\nTest categorical accuracy: %.4f'% (score_sdr_tf[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Prediction Perfomance of **standardized** TF-IDF  model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from app.visualization import (plot_prediction_metrics,\n",
    "                               create_clf_report,\n",
    "                               plot_roc_curve,\n",
    "                               plot_precision_recall_curve,\n",
    "                               plot_confusion_matrix)\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "prediction_val_sdr_tf = model_sdr_tf.predict(model_data_sdr_tf['x_test'],\n",
    "                                             batch_size=best_model_sdr_params['batch_size'])\n",
    "\n",
    "# returns each entry result to the classification with the relevant probabilities\n",
    "y_pred_processed_sdr_tf = np.array([np.argmax(val) for val in prediction_val_sdr_tf])\n",
    "y_true_processed_sdr_tf = np.array([np.argmax(val) for val in model_data_sdr_tf['y_test']])\n",
    "\n",
    "# If you want to get the Classification Report, comment out the below line\n",
    "create_clf_report(y_true_processed_sdr_tf, y_pred_processed_sdr_tf , Classes)\n",
    "\n",
    "# If you want to get the confusion matrix,comment out the below line\n",
    "plot_confusion_matrix(y_true_processed_sdr_tf, y_pred_processed_sdr_tf , Classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
